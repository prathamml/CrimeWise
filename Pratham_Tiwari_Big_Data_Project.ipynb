{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pratham Tiwari Big Data Project"
      ],
      "metadata": {
        "id": "qu22LtAgZbHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Spark Setup and Data Extraction"
      ],
      "metadata": {
        "id": "zu3xP2MfZmwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uGzNMOcqX-Rx"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "spark = pyspark.sql.SparkSession.builder.appName(\"Pratham Big Data Project\").getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgjBgopOZVSg",
        "outputId": "a2715da4-250c-4e38-9f1b-27579383ab2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
            "|              Dates|      Category|            Descript|DayOfWeek|PdDistrict|    Resolution|             Address|                  X|                 Y|\n",
            "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
            "|2015-05-13 23:53:00|      WARRANTS|      WARRANT ARREST|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST|  -122.425891675136|  37.7745985956747|\n",
            "|2015-05-13 23:53:00|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST|  -122.425891675136|  37.7745985956747|\n",
            "|2015-05-13 23:33:00|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|VANNESS AV / GREE...|   -122.42436302145|  37.8004143219856|\n",
            "|2015-05-13 23:30:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|  NORTHERN|          NONE|1500 Block of LOM...|-122.42699532676599| 37.80087263276921|\n",
            "|2015-05-13 23:30:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|      PARK|          NONE|100 Block of BROD...|  -122.438737622757|37.771541172057795|\n",
            "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower\n",
        "\n",
        "df = spark.read.format('csv')\\\n",
        "    .option('header', 'true')\\\n",
        "    .option('inferSchema', 'true')\\\n",
        "    .load('train.csv')\n",
        "\n",
        "data = df.select(\n",
        "    lower(col('Category')).alias('Category'),\n",
        "    lower(col('Descript')).alias('Description')\n",
        ")\n",
        "\n",
        "data.cache()\n",
        "\n",
        "print('Dataframe Structure')\n",
        "print('----------------------------------')\n",
        "data.printSchema()\n",
        "\n",
        "print('\\nDataframe preview')\n",
        "print('----------------------------------')\n",
        "data.show(5)\n",
        "\n",
        "print('\\nTotal number of rows:', df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFshAvqraQfy",
        "outputId": "880e6a98-e211-49c7-9aa1-096ee88bbbdf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe Structure\n",
            "----------------------------------\n",
            "root\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            "\n",
            "\n",
            "Dataframe preview\n",
            "----------------------------------\n",
            "+--------------+--------------------+\n",
            "|      Category|         Description|\n",
            "+--------------+--------------------+\n",
            "|      warrants|      warrant arrest|\n",
            "|other offenses|traffic violation...|\n",
            "|other offenses|traffic violation...|\n",
            "| larceny/theft|grand theft from ...|\n",
            "| larceny/theft|grand theft from ...|\n",
            "+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Total number of rows: 878049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "def top_n_list(df, var, N):\n",
        "\n",
        "    total_unique = df.select(var).distinct().count()\n",
        "    print(f\"Total number of unique values in '{var}': {total_unique}\\n\")\n",
        "    print(f\"Top {N} most frequent values in '{var}':\")\n",
        "\n",
        "    df.groupBy(var).count()\\\n",
        "      .withColumnRenamed('count', 'totalValue')\\\n",
        "      .orderBy(col('totalValue').desc())\\\n",
        "      .show(N, truncate=False)\n",
        "\n",
        "top_n_list(data, 'Category', 10)\n",
        "print('\\n')\n",
        "top_n_list(data, 'Description', 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt1ctZD6aZfD",
        "outputId": "c583c0cd-1ba7-467b-d092-7c423ae1223f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique values in 'Category': 39\n",
            "\n",
            "Top 10 most frequent values in 'Category':\n",
            "+--------------+----------+\n",
            "|Category      |totalValue|\n",
            "+--------------+----------+\n",
            "|larceny/theft |174900    |\n",
            "|other offenses|126182    |\n",
            "|non-criminal  |92304     |\n",
            "|assault       |76876     |\n",
            "|drug/narcotic |53971     |\n",
            "|vehicle theft |53781     |\n",
            "|vandalism     |44725     |\n",
            "|warrants      |42214     |\n",
            "|burglary      |36755     |\n",
            "|suspicious occ|31414     |\n",
            "+--------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "\n",
            "Total number of unique values in 'Description': 879\n",
            "\n",
            "Top 10 most frequent values in 'Description':\n",
            "+-----------------------------------------+----------+\n",
            "|Description                              |totalValue|\n",
            "+-----------------------------------------+----------+\n",
            "|grand theft from locked auto             |60022     |\n",
            "|lost property                            |31729     |\n",
            "|battery                                  |27441     |\n",
            "|stolen automobile                        |26897     |\n",
            "|drivers license, suspended or revoked    |26839     |\n",
            "|warrant arrest                           |23754     |\n",
            "|suspicious occurrence                    |21891     |\n",
            "|aided case, mental disturbed             |21497     |\n",
            "|petty theft from locked auto             |19771     |\n",
            "|malicious mischief, vandalism of vehicles|17789     |\n",
            "+-----------------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.select('Category').distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAt3ysKJaoq5",
        "outputId": "de1d5907-0b32-40d1-d7b7-8a2b0a440e4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training, test = data.randomSplit([0.7,0.3], seed=60)\n",
        "print(\"Training Dataset Count:\", training.count())\n",
        "print(\"Test Dataset Count:\", test.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqNI0CccavsF",
        "outputId": "eb362379-7d63-4768-f598-b1a4eaeb93a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 614667\n",
            "Test Dataset Count: 263382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Pipeline Setup and Model Definition"
      ],
      "metadata": {
        "id": "G2NBHPMZbUyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, OneHotEncoder, StringIndexer, VectorAssembler, HashingTF, IDF, Word2Vec\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
        "\n",
        "regex_tokenizer = RegexTokenizer(pattern='\\\\W')\\\n",
        "                  .setInputCol(\"Description\")\\\n",
        "                  .setOutputCol(\"tokens\")\n",
        "\n",
        "extra_stopwords = ['http','amp','rt','t','c','the']\n",
        "stopwords_remover = StopWordsRemover()\\\n",
        "                    .setInputCol('tokens')\\\n",
        "                    .setOutputCol('filtered_words')\\\n",
        "                    .setStopWords(extra_stopwords)\n",
        "\n",
        "\n",
        "count_vectors = CountVectorizer(vocabSize=10000, minDF=5)\\\n",
        "               .setInputCol(\"filtered_words\")\\\n",
        "               .setOutputCol(\"features\")\n",
        "\n",
        "\n",
        "hashingTf = HashingTF(numFeatures=10000)\\\n",
        "            .setInputCol(\"filtered_words\")\\\n",
        "            .setOutputCol(\"raw_features\")\n",
        "\n",
        "idf = IDF(minDocFreq=5)\\\n",
        "        .setInputCol(\"raw_features\")\\\n",
        "        .setOutputCol(\"features\")\n",
        "\n",
        "word2Vec = Word2Vec(vectorSize=1000, minCount=0)\\\n",
        "           .setInputCol(\"filtered_words\")\\\n",
        "           .setOutputCol(\"features\")\n",
        "\n",
        "label_string_idx = StringIndexer()\\\n",
        "                  .setInputCol(\"Category\")\\\n",
        "                  .setOutputCol(\"label\")\n",
        "\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "nb = NaiveBayes(smoothing=1)\n",
        "\n",
        "def metrics_ev(labels, metrics):\n",
        "\n",
        "    print(\"---------Confusion matrix-----------------\")\n",
        "    print(metrics.confusionMatrix)\n",
        "    print(' ')\n",
        "\n",
        "    print('----------Overall statistics-----------')\n",
        "    print(\"Precision = %s\" %  metrics.precision())\n",
        "    print(\"Recall = %s\" %  metrics.recall())\n",
        "    print(\"F1 Score = %s\" % metrics.fMeasure())\n",
        "    print(' ')\n",
        "\n",
        "    print('----------Statistics by class----------')\n",
        "    for label in sorted(labels):\n",
        "       print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
        "       print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
        "       print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
        "    print(' ')\n",
        "\n",
        "    print('----------Weighted stats----------------')\n",
        "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
        "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
        "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
        "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
        "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)"
      ],
      "metadata": {
        "id": "8tXyOeDEcKMA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Build Multi-Classification"
      ],
      "metadata": {
        "id": "FptAYS56cgxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3a.Logistic Regression with Count Vector Features"
      ],
      "metadata": {
        "id": "DaOJO4xbcobN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "pipeline_cv_lr = Pipeline().setStages([regex_tokenizer, stopwords_remover, count_vectors, label_string_idx, lr])\n",
        "model_cv_lr = pipeline_cv_lr.fit(training)\n",
        "predictions_cv_lr = model_cv_lr.transform(test)"
      ],
      "metadata": {
        "id": "-1jt-oq6czQM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----------------------------Check Top 5 predictions----------------------------------')\n",
        "predictions_cv_lr.select('Description', 'Category', 'probability', 'label', 'prediction')\\\n",
        "                  .orderBy(\"probability\", ascending=False)\\\n",
        "                  .show(n=5, truncate=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSokHssDdo6Z",
        "outputId": "932f6718-06ab-48be-f7d7-2182f3844df4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------Check Top 5 predictions----------------------------------\n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "|                   Description|     Category|                   probability|label|prediction|\n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8738390105611061,0.02048...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8738390105611061,0.02048...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8738390105611061,0.02048...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8738390105611061,0.02048...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8738390105611061,0.02048...|  0.0|       0.0|\n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_cv_lr = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy = evaluator_cv_lr.evaluate(predictions_cv_lr)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "precision_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedPrecision\")\n",
        "precision = precision_evaluator.evaluate(predictions_cv_lr)\n",
        "print(f'Precision: {precision}')\n",
        "\n",
        "recall_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedRecall\")\n",
        "recall = recall_evaluator.evaluate(predictions_cv_lr)\n",
        "print(f'Recall: {recall}')\n",
        "\n",
        "f1_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"f1\")\n",
        "f1_score = f1_evaluator.evaluate(predictions_cv_lr)\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "rmse_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")\n",
        "rmse = rmse_evaluator.evaluate(predictions_cv_lr)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mse_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mse\")\n",
        "mse = mse_evaluator.evaluate(predictions_cv_lr)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "mae_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mae\")\n",
        "mae = mae_evaluator.evaluate(predictions_cv_lr)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "r2_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"r2\")\n",
        "r2 = r2_evaluator.evaluate(predictions_cv_lr)\n",
        "print(f'R-Squared: {r2}')\n",
        "\n",
        "def calculate_mape(predictions):\n",
        "    return predictions.withColumn(\"mape\", F.abs((col(\"label\") - col(\"prediction\")) / col(\"label\")) * 100)\n",
        "\n",
        "predictions_mape = calculate_mape(predictions_cv_lr)\n",
        "mape = predictions_mape.agg(F.avg(\"mape\")).collect()[0][0]\n",
        "print(f'MAPE: {mape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR2AK9ipdxf2",
        "outputId": "5a5809d6-ead3-4bdf-fc1a-945607ff2ce5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9780281112604506\n",
            "Precision: 0.9724534113698968\n",
            "Recall: 0.9780281112604506\n",
            "F1 Score: 0.9720379224200315\n",
            "RMSE: 3.0462195287716347\n",
            "MSE: 9.27945341746968\n",
            "MAE: 0.42185494832600556\n",
            "R-Squared: 0.6943280931074408\n",
            "MAPE: 2.5339090007843796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3b.Apply Naive Bayes with Count Vector Features"
      ],
      "metadata": {
        "id": "4a_h3shRd6re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_cv_nb = Pipeline().setStages([regex_tokenizer, stopwords_remover, count_vectors, label_string_idx, nb])\n",
        "model_cv_nb = pipeline_cv_nb.fit(training)\n",
        "predictions_cv_nb = model_cv_nb.transform(test)"
      ],
      "metadata": {
        "id": "yU25VodTd_nY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
        "accuracy = accuracy_evaluator.evaluate(predictions_cv_nb)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "precision_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedPrecision\")\n",
        "precision = precision_evaluator.evaluate(predictions_cv_nb)\n",
        "print(f'Precision: {precision}')\n",
        "\n",
        "recall_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedRecall\")\n",
        "recall = recall_evaluator.evaluate(predictions_cv_nb)\n",
        "print(f'Recall: {recall}')\n",
        "\n",
        "f1_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"f1\")\n",
        "f1_score = f1_evaluator.evaluate(predictions_cv_nb)\n",
        "print(f'F1 Score: {f1_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnnVn0PuiGnG",
        "outputId": "c7950edf-df3c-4b93-c0b1-56ab81ab6994"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.993268332687883\n",
            "Precision: 0.9941741818988308\n",
            "Recall: 0.993268332687883\n",
            "F1 Score: 0.99350875457078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3c.Logistic Regression Using TF-IDF Features"
      ],
      "metadata": {
        "id": "uOgVxj04jRg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_idf_lr = Pipeline().setStages([regex_tokenizer, stopwords_remover, hashingTf, idf, label_string_idx, lr])\n",
        "model_idf_lr = pipeline_idf_lr.fit(training)\n",
        "predictions_idf_lr = model_idf_lr.transform(test)"
      ],
      "metadata": {
        "id": "hY615WYhjWKi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----------------------------Check Top 5 predictions----------------------------------')\n",
        "print(' ')\n",
        "predictions_idf_lr.select('Description','Category',\"probability\",\"label\",\"prediction\")\\\n",
        "                                        .orderBy(\"probability\", ascending=False)\\\n",
        "                                        .show(n=5, truncate=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP7lKUr5kSQB",
        "outputId": "932643b5-2184-4f0b-b6b4-28926bb9cd38"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------Check Top 5 predictions----------------------------------\n",
            " \n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "|                   Description|     Category|                   probability|label|prediction|\n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8845322339589967,0.01879...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8845322339589967,0.01879...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8845322339589967,0.01879...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8845322339589967,0.01879...|  0.0|       0.0|\n",
            "|theft, bicycle, <$50, no se...|larceny/theft|[0.8845322339589967,0.01879...|  0.0|       0.0|\n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
        "accuracy = accuracy_evaluator.evaluate(predictions_idf_lr)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "precision_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedPrecision\")\n",
        "precision = precision_evaluator.evaluate(predictions_idf_lr)\n",
        "print(f'Precision: {precision}')\n",
        "\n",
        "recall_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedRecall\")\n",
        "recall = recall_evaluator.evaluate(predictions_idf_lr)\n",
        "print(f'Recall: {recall}')\n",
        "\n",
        "f1_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"f1\")\n",
        "f1_score = f1_evaluator.evaluate(predictions_idf_lr)\n",
        "print(f'F1 Score: {f1_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThIMocvWk3Bs",
        "outputId": "43659401-fbfb-410b-e8cb-1e7705795085"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9780167209604301\n",
            "Precision: 0.9725160742029567\n",
            "Recall: 0.97801672096043\n",
            "F1 Score: 0.9719229068954107\n"
          ]
        }
      ]
    }
  ]
}